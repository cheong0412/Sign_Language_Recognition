# train.py

from CNNLSTM_3D import CNNLSTMModel_3D
from Video_Dataset import SignLanguageDataset  # <- ë°ì´í„°ì…‹ í´ëž˜ìŠ¤ë§Œ ê°€ì ¸ì˜´

import pandas as pd
import torch
from torch.utils.data import DataLoader, Subset
from sklearn.model_selection import train_test_split
from collections import defaultdict
import os

# ëª¨ë¸ ì €ìž¥ í´ë” ìƒì„±
save_dir = './2_NEW_3D_Layer6_Batch11_CNN_LSTM'
os.makedirs(save_dir, exist_ok=True)


# # A100 80GBì˜ ì ˆë°˜ì¸ 0.5ë¡œ ì œí•œ
# # VRAM ë©”ëª¨ë¦¬ëŸ‰ ì œí•œ ì„¤ì •
# torch.cuda.set_per_process_memory_fraction(0.5, device=0)
# device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# # ë””ë°”ì´ìŠ¤ í™•ì¸
# print(f"Using device: {device}", flush=True)

# ------------------------------------------------------------------------
# (transform ì¶”ê°€í•¨.)
# ------------------------------------------------------------------------
from torchvision import transforms  
# ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì •ì˜
image_transform = transforms.Compose([
    # transforms.Resize((720, 1280)),  # ëª¨ë¸ ìž…ë ¥ì— ë§žê²Œ resize
    # transforms.Resize((360, 640)), # ì´ë¯¸ì§€ ì¤„ì´ë˜ ë¹„ìœ¨ì€ ìœ ì§€
    transforms.ToTensor(),
    transforms.Normalize([0.5]*3, [0.5]*3)  # ì •ê·œí™”
])

# ------------------------------------------------------------------------
# [1] ë¼ë²¨ ë¶ˆëŸ¬ì˜¤ê¸° (ì—‘ì…€ì—ì„œ)
# ------------------------------------------------------------------------
label_df = pd.read_excel(r'G:\Team5\DATA\New_Final_Video_Label_Index.xlsx')
label_dict = label_df.set_index('File_name')['Korean'].to_dict()
label_to_idx = label_df.set_index('Korean')['Label_Index'].to_dict()

# ------------------------------------------------------------------------
# [2] Dataset ìƒì„± (transform ì¶”ê°€í•¨.)
# ------------------------------------------------------------------------
dataset = SignLanguageDataset(
    frames_dir=r'G:\Team5\DATA\New_Final_Crop_Rotate_Resize',
    keypoints_dir=r'G:\Team5\DATA\New_Final_npy',
    label_dict=label_dict,
    label_to_idx=label_to_idx,
    transform = image_transform
)

# ------------------------------------------------------------------------
# [3] Split: ë¼ë²¨ë³„ë¡œ 7:2:1
# ------------------------------------------------------------------------
label_to_indices = defaultdict(list)
for idx, sample in enumerate(dataset.samples):
    label = sample['label']
    label_to_indices[label].append(idx)

train_indices, valid_indices, test_indices = [], [], []

# ë¼ë²¨ë³„ë¡œ ë¶„í• 
for label, indices in label_to_indices.items():
    train, temp = train_test_split(indices, test_size=0.3, random_state=42)
    valid, test = train_test_split(temp, test_size=2/3, random_state=42)
    
    train_indices.extend(train)
    valid_indices.extend(valid)
    test_indices.extend(test)
    
print(f"Split complete. Train: {len(train_indices)}, Valid: {len(valid_indices)}, Test: {len(test_indices)}", flush=True)

# ------------------------------------------------------------------------
# [4] DataLoader ìƒì„±
# ------------------------------------------------------------------------
train_loader = DataLoader(Subset(dataset, train_indices), batch_size=11, shuffle=True)
valid_loader = DataLoader(Subset(dataset, valid_indices), batch_size=11, shuffle=False)
test_loader  = DataLoader(Subset(dataset, test_indices),  batch_size=11, shuffle=False)
print("DataLoaders created.", flush=True)
# ------------------------------------------------------------------------
# [5] ëª¨ë¸ ì¤€ë¹„
# ------------------------------------------------------------------------
# torch.cuda.set_per_process_memory_fraction(0.5, device=0)
# device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# âœ… ë””ë°”ì´ìŠ¤ í™•ì¸
device = 'cuda' if torch.cuda.is_available() else 'cpu'
num_classes = len(label_to_idx)
model = CNNLSTMModel_3D(num_classes=num_classes).to(device)

### âœ… ì €ìž¥í•œ ëª¨ë¸ ë¡œë”© âœ…  - í•™ìŠµì‹œí‚¬ ë•Œ ëŠê²¼ì„ ê²½ìš°!!!!!
state_dict = torch.load(r'G:\Team5\NEW_3D_Layer6_Batch11_CNN_LSTM\best_weight_ep17_trainL1.11_trainA53.01_valL1.18_valA50.62.pt')
model.load_state_dict(state_dict)

# ------------------------------------------------------------------------
# [6] ì†ì‹¤í•¨ìˆ˜, ì˜µí‹°ë§ˆì´ì €
# ------------------------------------------------------------------------
from collections import Counter

# í´ëž˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜ ê³„ì‚°
class_counts = Counter([sample['label'] for sample in dataset.samples])

# ê°€ì¤‘ì¹˜ ê³„ì‚° (ì „ì²´ ìƒ˜í”Œ ìˆ˜ / ê° í´ëž˜ìŠ¤ ìƒ˜í”Œ ìˆ˜)
num_samples = sum(class_counts.values())
weights = [num_samples / class_counts[i] for i in range(len(class_counts))]
class_weights = torch.tensor(weights, dtype=torch.float).to(device)

# CrossEntropyLossì— í´ëž˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©
criterion = torch.nn.CrossEntropyLoss(weight=class_weights)
optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)

# ------------------------------------------------------------------------
# [7] í•™ìŠµ ë£¨í”„ + ì„±ëŠ¥ ì¶œë ¥ + Best ëª¨ë¸ ì €ìž¥
# ------------------------------------------------------------------------ 
num_epochs = 100
best_valid_loss = float('inf')  # Best ëª¨ë¸ íŒë‹¨ ê¸°ì¤€

for epoch in range(num_epochs):
    print(f"\nðŸ” [Epoch {epoch+1}/{num_epochs}] ----------------------------")
    
    # ------- Train -------
    model.train()
    running_loss = 0.0
    correct = 0
    total = 0

    for i, (img_seq, keypoints, labels) in enumerate(train_loader):
        print(f"ðŸŒ€ [Train] Epoch {epoch+1}, Step {i+1}/{len(train_loader)} - Loading batch...", flush=True)

        img_seq, labels = img_seq.to(device), labels.to(device)

        optimizer.zero_grad()
        outputs = model(img_seq, keypoints)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

        _, predicted = torch.max(outputs, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

        # ðŸ”¹ ìŠ¤í…ë³„ ì¶œë ¥
        print(f"  â–¶ Step {i+1}/{len(train_loader)} | Batch Loss: {loss.item():.4f}", flush=True)

    train_loss = running_loss / len(train_loader)
    train_acc = 100 * correct / total
    print(f"ðŸ“Š Train Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%", flush=True)

    # ------- Validation -------
    model.eval()
    valid_loss = 0.0
    val_correct = 0
    val_total = 0

    with torch.no_grad():
        for img_seq, keypoints, labels in valid_loader:
            img_seq, labels = img_seq.to(device), labels.to(device)
            outputs = model(img_seq, keypoints)
            loss = criterion(outputs, labels)
            valid_loss += loss.item()

            _, predicted = torch.max(outputs, 1)
            val_total += labels.size(0)
            val_correct += (predicted == labels).sum().item()

    avg_valid_loss = valid_loss / len(valid_loader)
    valid_acc = 100 * val_correct / val_total
    print(f"âœ… Valid Loss: {avg_valid_loss:.4f} | Accuracy: {valid_acc:.2f}%", flush=True)

    # ------- Best ëª¨ë¸ ì €ìž¥ -------
    if avg_valid_loss < best_valid_loss:
        best_valid_loss = avg_valid_loss
        filename = (
            f'best_weight_ep{epoch+1}_'
            f'trainL{train_loss:.2f}_trainA{train_acc:.2f}_'
            f'valL{avg_valid_loss:.2f}_valA{valid_acc:.2f}.pt'
        )
        save_path = os.path.join(save_dir, filename)
        torch.save(model.state_dict(), save_path)
        print(f"ðŸ“¦ Best model saved at epoch {epoch+1}! [{filename}]", flush=True)