import cv2
import os
import mediapipe as mp
import numpy as np
from tqdm import tqdm
import torch

# âœ… ë””ë°”ì´ìŠ¤ í™•ì¸
torch.cuda.set_per_process_memory_fraction(0.5, device=0)
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}", flush=True)

# âœ… ì…ë ¥ ë° ì¶œë ¥ ê²½ë¡œ ì„¤ì •
FRAMES_DIR = r'G:\Team5\DATA\Final_Data\Word\New_Final_Crop_Rotate_Resize'  # í”„ë ˆì„ ì´ë¯¸ì§€ê°€ ìˆëŠ” ë£¨íŠ¸ í´ë”
KEYPOINTS_DIR = r'G:\Team5\DATA\Final_Data\Word\Final_npy'               # ê´€ì ˆ ì¢Œí‘œ ì €ì¥ í´ë”
os.makedirs(KEYPOINTS_DIR, exist_ok=True)

# âœ… MediaPipe ì´ˆê¸°í™”
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=True, max_num_hands=2, min_detection_confidence=0.5)

# âœ… ì˜ìƒ í´ë” ë¦¬ìŠ¤íŠ¸
video_names = sorted(os.listdir(FRAMES_DIR))
print(f"ğŸ ì´ {len(video_names)}ê°œ ì˜ìƒ í´ë” ì²˜ë¦¬ ì‹œì‘", flush=True)

# âœ… ì´ì–´ì„œ ì‹¤í–‰í•˜ë©´ì„œ ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥
for video_name in video_names:
    frame_folder = os.path.join(FRAMES_DIR, video_name)
    keypoint_output_dir = os.path.join(KEYPOINTS_DIR, video_name)
    os.makedirs(keypoint_output_dir, exist_ok=True)

    print(f'\nğŸ“‚ í˜„ì¬ ì²˜ë¦¬ ì¤‘: {video_name}')
    frame_files = sorted([f for f in os.listdir(frame_folder) if f.lower().endswith('.jpg')])

    for frame_file in frame_files:
        npy_expected = frame_file.replace('.jpg', f'_hand0.npy')  # ìµœì†Œ í•˜ë‚˜ì˜ ì† íŒŒì¼ ê¸°ì¤€
        npy_path = os.path.join(keypoint_output_dir, npy_expected)

        if os.path.exists(npy_path):
            continue  # ì´ë¯¸ ì²˜ë¦¬ëœ í”„ë ˆì„ì€ ê±´ë„ˆë›°ê¸°

        frame_path = os.path.join(frame_folder, frame_file)
        frame = cv2.imread(frame_path)
        if frame is None:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {frame_path}")
            continue

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = hands.process(rgb)

        if results.multi_hand_landmarks:
            for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):
                coords = []
                for lm in hand_landmarks.landmark:
                    coords.extend([lm.x, lm.y, lm.z])

                npy_name = frame_file.replace('.jpg', f'_hand{hand_idx}.npy')
                np_file = os.path.join(keypoint_output_dir, npy_name)
                np.save(npy_file := np_file, np.array(coords))
                print(f"âœ… ì €ì¥ ì™„ë£Œ: {npy_file}")
        else:
            print(f"âŒ ì† ë¯¸ê²€ì¶œ: {frame_path}")

hands.close()
print("\nâœ… ì¤‘ë‹¨ ì§€ì ë¶€í„° ì´ì–´ì„œ ê´€ì ˆ ì¶”ì¶œ ì™„ë£Œ")
